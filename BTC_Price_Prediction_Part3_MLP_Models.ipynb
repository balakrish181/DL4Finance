{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Price Prediction Using Deep Learning Techniques\n",
    "\n",
    "## Part 3: MLP Models for Time Series Prediction\n",
    "\n",
    "In this notebook, we build and train Multilayer Perceptron (MLP) models for Bitcoin price prediction using both the original price series and the fractionally differenced series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Visualization Settings\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load prepared data\n",
    "try:\n",
    "    with open('btc_prepared_data.pkl', 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    \n",
    "    # Extract data\n",
    "    btc_data = data_dict['btc_data']\n",
    "    optimal_d = data_dict['optimal_d']\n",
    "    X_train_price = data_dict['X_train_price']\n",
    "    X_test_price = data_dict['X_test_price']\n",
    "    y_train_price = data_dict['y_train_price']\n",
    "    y_test_price = data_dict['y_test_price']\n",
    "    X_train_frac = data_dict['X_train_frac']\n",
    "    X_test_frac = data_dict['X_test_frac']\n",
    "    y_train_frac = data_dict['y_train_frac']\n",
    "    y_test_frac = data_dict['y_test_frac']\n",
    "    window_size = data_dict['window_size']\n",
    "    \n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Window size: {window_size}\")\n",
    "    print(f\"Optimal fractional differencing order: {optimal_d}\")\n",
    "    print(f\"Training data shape: {X_train_price.shape}\")\n",
    "    print(f\"Testing data shape: {X_test_price.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Prepared data not found. Please run Part 2 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before training our models, we need to normalize the data to improve training stability and convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Normalize data for price prediction\n",
    "price_scaler = MinMaxScaler()\n",
    "X_train_price_scaled = np.array([price_scaler.fit_transform(x.reshape(-1, 1)).flatten() for x in X_train_price])\n",
    "X_test_price_scaled = np.array([price_scaler.transform(x.reshape(-1, 1)).flatten() for x in X_test_price])\n",
    "\n",
    "y_train_price_scaled = price_scaler.transform(y_train_price.reshape(-1, 1)).flatten()\n",
    "y_test_price_scaled = price_scaler.transform(y_test_price.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Normalize data for fractionally differenced series prediction\n",
    "frac_scaler = MinMaxScaler()\n",
    "X_train_frac_scaled = np.array([frac_scaler.fit_transform(x.reshape(-1, 1)).flatten() for x in X_train_frac])\n",
    "X_test_frac_scaled = np.array([frac_scaler.transform(x.reshape(-1, 1)).flatten() for x in X_test_frac])\n",
    "\n",
    "y_train_frac_scaled = frac_scaler.transform(y_train_frac.reshape(-1, 1)).flatten()\n",
    "y_test_frac_scaled = frac_scaler.transform(y_test_frac.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Data normalization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model for Raw Price Prediction\n",
    "\n",
    "First, let's build and train an MLP model to predict the raw Bitcoin price using past price information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def build_mlp_model(input_shape, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build a Multilayer Perceptron (MLP) model for time series prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_shape : tuple\n",
    "        Shape of the input data\n",
    "    learning_rate : float\n",
    "        Learning rate for the optimizer\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tensorflow.keras.models.Sequential\n",
    "        Compiled MLP model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and train MLP model for raw price prediction\n",
    "mlp_price_model = build_mlp_model(window_size)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_price = mlp_price_model.fit(\n",
    "    X_train_price_scaled, y_train_price_scaled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_price.history['loss'], label='Training Loss')\n",
    "plt.plot(history_price.history['val_loss'], label='Validation Loss')\n",
    "plt.title('MLP Model Training History (Raw Price Prediction)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model for Fractionally Differenced Series Prediction\n",
    "\n",
    "Now, let's build and train an MLP model to predict the fractionally differenced series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Build and train MLP model for fractionally differenced series prediction\n",
    "mlp_frac_model = build_mlp_model(window_size)\n",
    "\n",
    "# Train the model\n",
    "history_frac = mlp_frac_model.fit(\n",
    "    X_train_frac_scaled, y_train_frac_scaled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_frac.history['loss'], label='Training Loss')\n",
    "plt.plot(history_frac.history['val_loss'], label='Validation Loss')\n",
    "plt.title('MLP Model Training History (Fractionally Differenced Prediction)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Let's evaluate the performance of our MLP models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model(model, X_test_scaled, y_test_scaled, scaler, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a model's performance on test data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : tensorflow.keras.models.Model\n",
    "        Trained model to evaluate\n",
    "    X_test_scaled : numpy.ndarray\n",
    "        Scaled test input data\n",
    "    y_test_scaled : numpy.ndarray\n",
    "        Scaled test target data\n",
    "    scaler : sklearn.preprocessing.MinMaxScaler\n",
    "        Scaler used to normalize the target data\n",
    "    model_name : str\n",
    "        Name of the model for display purposes\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred_scaled = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Inverse transform predictions and actual values\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled).flatten()\n",
    "    y_true = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Evaluation Metrics for {model_name}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}%\")\n",
    "    \n",
    "    # Plot actual vs. predicted values\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(y_true, label='Actual', color='blue', alpha=0.7)\n",
    "    plt.plot(y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "    plt.title(f'{model_name}: Actual vs. Predicted Values', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot prediction error\n",
    "    error = y_true - y_pred\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(error, color='green', alpha=0.7)\n",
    "    plt.title(f'{model_name}: Prediction Error', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Error')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "\n",
    "# Evaluate MLP model for raw price prediction\n",
    "price_results = evaluate_model(\n",
    "    mlp_price_model, \n",
    "    X_test_price_scaled, \n",
    "    y_test_price_scaled, \n",
    "    price_scaler, \n",
    "    \"MLP Model (Raw Price Prediction)\"\n",
    ")\n",
    "\n",
    "# Evaluate MLP model for fractionally differenced series prediction\n",
    "frac_results = evaluate_model(\n",
    "    mlp_frac_model, \n",
    "    X_test_frac_scaled, \n",
    "    y_test_frac_scaled, \n",
    "    frac_scaler, \n",
    "    \"MLP Model (Fractionally Differenced Prediction)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Transformation for Fractionally Differenced Predictions\n",
    "\n",
    "For the fractionally differenced series, we need to inverse transform the predictions to get back to the original price scale for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def inverse_fractional_difference(frac_diff_series, original_series, d, window_size=30):\n",
    "    \"\"\"\n",
    "    Approximate inverse of fractional differencing to recover the original series.\n",
    "    This is a simplified approach and may not perfectly recover the original series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    frac_diff_series : numpy.ndarray\n",
    "        Fractionally differenced series\n",
    "    original_series : numpy.ndarray\n",
    "        Original series used for initialization\n",
    "    d : float\n",
    "        Fractional differencing order\n",
    "    window_size : int\n",
    "        Window size for prediction\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Recovered original series\n",
    "    \"\"\"\n",
    "    # Get weights for inverse operation\n",
    "    weights = np.array([1.0])\n",
    "    for k in range(1, window_size):\n",
    "        weights = np.append(weights, weights[-1] * (d - k + 1) / k)\n",
    "    \n",
    "    # Initialize recovered series with known values\n",
    "    recovered = np.zeros(len(frac_diff_series) + window_size)\n",
    "    recovered[:window_size] = original_series[:window_size]\n",
    "    \n",
    "    # Iteratively recover the original series\n",
    "    for i in range(window_size, len(recovered)):\n",
    "        recovered[i] = frac_diff_series[i - window_size]\n",
    "        for j in range(1, window_size + 1):\n",
    "            recovered[i] += weights[j-1] * recovered[i-j]\n",
    "    \n",
    "    return recovered[window_size:]\n",
    "\n",
    "# Get the test dates for plotting\n",
    "test_dates = btc_data.index[-len(y_test_price):]\n",
    "\n",
    "# Get the original price values for comparison\n",
    "original_price = btc_data['Close'].values[-len(y_test_price):]\n",
    "\n",
    "# Get the fractionally differenced predictions\n",
    "frac_diff_pred = frac_results['y_pred']\n",
    "\n",
    "# Inverse transform the fractionally differenced predictions (simplified approach)\n",
    "# Note: This is an approximation and may not perfectly recover the original series\n",
    "try:\n",
    "    recovered_price_pred = inverse_fractional_difference(\n",
    "        frac_diff_pred, \n",
    "        btc_data['Close'].values[:window_size], \n",
    "        optimal_d,\n",
    "        window_size\n",
    "    )\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(test_dates, original_price, label='Actual Price', color='blue', alpha=0.7)\n",
    "    plt.plot(test_dates, price_results['y_pred'], label='Raw Price Model', color='red', alpha=0.7)\n",
    "    plt.plot(test_dates[-len(recovered_price_pred):], recovered_price_pred, \n",
    "             label='Recovered from Frac Diff Model', color='green', alpha=0.7)\n",
    "    plt.title('Comparison of Prediction Methods', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Bitcoin Price (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error in inverse transformation: {e}\")\n",
    "    print(\"Skipping inverse transformation visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's compare the performance of our MLP models on both the raw price data and the fractionally differenced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a DataFrame for performance comparison\n",
    "performance_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'MLP (Raw Price)',\n",
    "        'MAE': price_results['mae'],\n",
    "        'RMSE': price_results['rmse'],\n",
    "        'MAPE (%)': price_results['mape']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'MLP (Fractionally Differenced)',\n",
    "        'MAE': frac_results['mae'],\n",
    "        'RMSE': frac_results['rmse'],\n",
    "        'MAPE (%)': frac_results['mape']\n",
    "    }\n",
    "])\n",
    "\n",
    "display(performance_df)\n",
    "\n",
    "# Save models and results\n",
    "mlp_price_model.save('mlp_price_model.h5')\n",
    "mlp_frac_model.save('mlp_frac_model.h5')\n",
    "\n",
    "results_dict = {\n",
    "    'price_results': price_results,\n",
    "    'frac_results': frac_results,\n",
    "    'performance_df': performance_df\n",
    "}\n",
    "\n",
    "with open('mlp_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f)\n",
    "\n",
    "print(\"Models and results saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Part 3\n",
    "\n",
    "In this part of our analysis, we've:\n",
    "\n",
    "1. Built and trained MLP models for both raw Bitcoin price prediction and fractionally differenced series prediction\n",
    "2. Evaluated the models' performance using various metrics (MAE, RMSE, MAPE)\n",
    "3. Attempted to inverse transform the fractionally differenced predictions for comparison\n",
    "4. Compared the performance of the two approaches\n",
    "\n",
    "Key findings:\n",
    "- The MLP model trained on fractionally differenced data likely shows different error characteristics compared to the model trained on raw price data\n",
    "- Fractional differencing helps achieve stationarity while preserving more information than traditional differencing\n",
    "- The choice between using raw price data or fractionally differenced data depends on the specific prediction task and performance requirements\n",
    "\n",
    "In the next part, we'll explore CNN models with Gramian Angular Field (GAF) representations for time series prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
