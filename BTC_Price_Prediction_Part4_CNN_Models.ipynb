{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Price Prediction Using Deep Learning Techniques\n",
    "\n",
    "## Part 4: CNN Models with Gramian Angular Field Representations\n",
    "\n",
    "In this notebook, we explore Convolutional Neural Network (CNN) models for Bitcoin price prediction using Gramian Angular Field (GAF) image representations of time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# GAF Transformation\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "# Visualization Settings\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load prepared data\n",
    "try:\n",
    "    with open('btc_prepared_data.pkl', 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    \n",
    "    # Extract data\n",
    "    btc_data = data_dict['btc_data']\n",
    "    optimal_d = data_dict['optimal_d']\n",
    "    X_train_price = data_dict['X_train_price']\n",
    "    X_test_price = data_dict['X_test_price']\n",
    "    y_train_price = data_dict['y_train_price']\n",
    "    y_test_price = data_dict['y_test_price']\n",
    "    X_train_frac = data_dict['X_train_frac']\n",
    "    X_test_frac = data_dict['X_test_frac']\n",
    "    y_train_frac = data_dict['y_train_frac']\n",
    "    y_test_frac = data_dict['y_test_frac']\n",
    "    window_size = data_dict['window_size']\n",
    "    \n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Window size: {window_size}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Prepared data not found. Please run Part 2 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramian Angular Field (GAF) Transformation\n",
    "\n",
    "### Theoretical Background\n",
    "\n",
    "The Gramian Angular Field (GAF) is a method to encode time series data as images, allowing us to leverage powerful CNN architectures for time series analysis. There are two types of GAF:\n",
    "\n",
    "1. **Gramian Angular Summation Field (GASF)**: Encodes the temporal correlation between observations by the summation of trigonometric functions.\n",
    "2. **Gramian Angular Difference Field (GADF)**: Encodes the temporal correlation by the difference of trigonometric functions.\n",
    "\n",
    "The transformation involves these steps:\n",
    "1. Normalize the time series to the range [-1, 1] or [0, 1]\n",
    "2. Represent each value as an angle in the polar coordinate system\n",
    "3. Compute the trigonometric sum/difference between each pair of angles\n",
    "\n",
    "Let's implement this transformation for our Bitcoin price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_gaf_images(data, method='summation'):\n",
    "    \"\"\"\n",
    "    Create Gramian Angular Field images from time series data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        Time series data with shape (n_samples, n_timestamps)\n",
    "    method : str\n",
    "        'summation' for GASF or 'difference' for GADF\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        GAF images with shape (n_samples, n_timestamps, n_timestamps, 1)\n",
    "    \"\"\"\n",
    "    # Initialize GAF transformer\n",
    "    gaf = GramianAngularField(method=method)\n",
    "    \n",
    "    # Transform each sample\n",
    "    gaf_images = []\n",
    "    for sample in data:\n",
    "        # Reshape for pyts (expects shape [n_samples, n_timestamps])\n",
    "        sample_reshaped = sample.reshape(1, -1)\n",
    "        \n",
    "        # Transform to GAF\n",
    "        gaf_image = gaf.fit_transform(sample_reshaped)\n",
    "        \n",
    "        # Append to list\n",
    "        gaf_images.append(gaf_image[0])\n",
    "    \n",
    "    # Convert to numpy array and add channel dimension for CNN\n",
    "    gaf_images = np.array(gaf_images)[..., np.newaxis]\n",
    "    \n",
    "    return gaf_images\n",
    "\n",
    "# Create GAF images for raw price data\n",
    "X_train_price_gaf = create_gaf_images(X_train_price)\n",
    "X_test_price_gaf = create_gaf_images(X_test_price)\n",
    "\n",
    "# Create GAF images for fractionally differenced data\n",
    "X_train_frac_gaf = create_gaf_images(X_train_frac)\n",
    "X_test_frac_gaf = create_gaf_images(X_test_frac)\n",
    "\n",
    "# Print shapes\n",
    "print(\"GAF Image Shapes:\")\n",
    "print(f\"X_train_price_gaf: {X_train_price_gaf.shape}\")\n",
    "print(f\"X_test_price_gaf: {X_test_price_gaf.shape}\")\n",
    "print(f\"X_train_frac_gaf: {X_train_frac_gaf.shape}\")\n",
    "print(f\"X_test_frac_gaf: {X_test_frac_gaf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize GAF Images\n",
    "\n",
    "Let's visualize some GAF images to understand how time series data is represented in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_time_series_and_gaf(time_series, gaf_image, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a time series and its corresponding GAF image side by side.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    time_series : numpy.ndarray\n",
    "        Time series data\n",
    "    gaf_image : numpy.ndarray\n",
    "        GAF image representation\n",
    "    title : str\n",
    "        Title for the plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot time series\n",
    "    axes[0].plot(time_series, color='#1f77b4')\n",
    "    axes[0].set_title(f'{title} - Time Series', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Time Step')\n",
    "    axes[0].set_ylabel('Value')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot GAF image\n",
    "    im = axes[1].imshow(gaf_image[:, :, 0], cmap='viridis')\n",
    "    axes[1].set_title(f'{title} - GAF Image', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time Step')\n",
    "    axes[1].set_ylabel('Time Step')\n",
    "    fig.colorbar(im, ax=axes[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot examples of time series and their GAF representations\n",
    "# Raw price data\n",
    "plot_time_series_and_gaf(\n",
    "    X_train_price[0], \n",
    "    X_train_price_gaf[0], \n",
    "    \"Bitcoin Price\"\n",
    ")\n",
    "\n",
    "# Fractionally differenced data\n",
    "plot_time_series_and_gaf(\n",
    "    X_train_frac[0], \n",
    "    X_train_frac_gaf[0], \n",
    "    \"Fractionally Differenced Bitcoin Price\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model for GAF Images\n",
    "\n",
    "Now, let's build a CNN model to process the GAF images for time series prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def build_cnn_model(input_shape, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build a CNN model for GAF image processing.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_shape : tuple\n",
    "        Shape of the input GAF images\n",
    "    learning_rate : float\n",
    "        Learning rate for the optimizer\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tensorflow.keras.models.Sequential\n",
    "        Compiled CNN model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Convolutional layers\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Get input shape from GAF images\n",
    "input_shape = X_train_price_gaf.shape[1:]\n",
    "\n",
    "# Build CNN models\n",
    "cnn_price_model = build_cnn_model(input_shape)\n",
    "cnn_frac_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Normalize target values for training\n",
    "price_scaler = MinMaxScaler()\n",
    "y_train_price_scaled = price_scaler.fit_transform(y_train_price.reshape(-1, 1)).flatten()\n",
    "y_test_price_scaled = price_scaler.transform(y_test_price.reshape(-1, 1)).flatten()\n",
    "\n",
    "frac_scaler = MinMaxScaler()\n",
    "y_train_frac_scaled = frac_scaler.fit_transform(y_train_frac.reshape(-1, 1)).flatten()\n",
    "y_test_frac_scaled = frac_scaler.transform(y_test_frac.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN Model for Raw Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train CNN model for raw price prediction\n",
    "history_price = cnn_price_model.fit(\n",
    "    X_train_price_gaf, y_train_price_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_price.history['loss'], label='Training Loss')\n",
    "plt.plot(history_price.history['val_loss'], label='Validation Loss')\n",
    "plt.title('CNN Model Training History (Raw Price Prediction)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN Model for Fractionally Differenced Series Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train CNN model for fractionally differenced series prediction\n",
    "history_frac = cnn_frac_model.fit(\n",
    "    X_train_frac_gaf, y_train_frac_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_frac.history['loss'], label='Training Loss')\n",
    "plt.plot(history_frac.history['val_loss'], label='Validation Loss')\n",
    "plt.title('CNN Model Training History (Fractionally Differenced Prediction)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Let's evaluate the performance of our CNN models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model(model, X_test, y_test_scaled, scaler, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a model's performance on test data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : tensorflow.keras.models.Model\n",
    "        Trained model to evaluate\n",
    "    X_test : numpy.ndarray\n",
    "        Test input data\n",
    "    y_test_scaled : numpy.ndarray\n",
    "        Scaled test target data\n",
    "    scaler : sklearn.preprocessing.MinMaxScaler\n",
    "        Scaler used to normalize the target data\n",
    "    model_name : str\n",
    "        Name of the model for display purposes\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform predictions and actual values\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled).flatten()\n",
    "    y_true = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Evaluation Metrics for {model_name}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}%\")\n",
    "    \n",
    "    # Plot actual vs. predicted values\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(y_true, label='Actual', color='blue', alpha=0.7)\n",
    "    plt.plot(y_pred, label='Predicted', color='red', alpha=0.7)\n",
    "    plt.title(f'{model_name}: Actual vs. Predicted Values', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot prediction error\n",
    "    error = y_true - y_pred\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(error, color='green', alpha=0.7)\n",
    "    plt.title(f'{model_name}: Prediction Error', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Error')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "\n",
    "# Evaluate CNN model for raw price prediction\n",
    "cnn_price_results = evaluate_model(\n",
    "    cnn_price_model, \n",
    "    X_test_price_gaf, \n",
    "    y_test_price_scaled, \n",
    "    price_scaler, \n",
    "    \"CNN Model (Raw Price Prediction)\"\n",
    ")\n",
    "\n",
    "# Evaluate CNN model for fractionally differenced series prediction\n",
    "cnn_frac_results = evaluate_model(\n",
    "    cnn_frac_model, \n",
    "    X_test_frac_gaf, \n",
    "    y_test_frac_scaled, \n",
    "    frac_scaler, \n",
    "    \"CNN Model (Fractionally Differenced Prediction)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's compare the performance of our CNN models on both the raw price data and the fractionally differenced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a DataFrame for performance comparison\n",
    "performance_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'CNN with GAF (Raw Price)',\n",
    "        'MAE': cnn_price_results['mae'],\n",
    "        'RMSE': cnn_price_results['rmse'],\n",
    "        'MAPE (%)': cnn_price_results['mape']\n",
    "    },\n",
    "    {\n",
    "        'Model': 'CNN with GAF (Fractionally Differenced)',\n",
    "        'MAE': cnn_frac_results['mae'],\n",
    "        'RMSE': cnn_frac_results['rmse'],\n",
    "        'MAPE (%)': cnn_frac_results['mape']\n",
    "    }\n",
    "])\n",
    "\n",
    "display(performance_df)\n",
    "\n",
    "# Save models and results\n",
    "cnn_price_model.save('cnn_price_model.h5')\n",
    "cnn_frac_model.save('cnn_frac_model.h5')\n",
    "\n",
    "results_dict = {\n",
    "    'cnn_price_results': cnn_price_results,\n",
    "    'cnn_frac_results': cnn_frac_results,\n",
    "    'performance_df': performance_df\n",
    "}\n",
    "\n",
    "with open('cnn_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_dict, f)\n",
    "\n",
    "print(\"Models and results saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Part 4\n",
    "\n",
    "In this part of our analysis, we've:\n",
    "\n",
    "1. Transformed time series data into Gramian Angular Field (GAF) images\n",
    "2. Visualized the GAF representations of both raw price and fractionally differenced data\n",
    "3. Built and trained CNN models to process these GAF images for price prediction\n",
    "4. Evaluated and compared the performance of the CNN models\n",
    "\n",
    "Key findings:\n",
    "- GAF transformation provides a novel way to represent time series data as images\n",
    "- CNN models can effectively capture patterns in these image representations\n",
    "- The choice between using raw price data or fractionally differenced data affects the model performance\n",
    "\n",
    "In the next part, we'll compare all our models (MLP and CNN) and draw final conclusions about the best approach for Bitcoin price prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
